{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a457ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Receives list of article codes and article counts.\n",
    "Scrapes IKEA website to obtain package dimensions (rounded up to next cm), weights (in kg rounded up 2 decimals) and counts.\n",
    "Returns list of package dimensions and weights.\n",
    "\"\"\"\n",
    "\n",
    "from willitfit.params import (\n",
    "    IKEA_COUNTRY_DOMAIN,\n",
    "    IKEA_WEBSITE_LANGUAGE,\n",
    "    WEBSITE_UNAVAILABLE,\n",
    "    ARTICLE_NOT_FOUND,\n",
    "    DATA_FOLDER,\n",
    "    ARTICLE_DATABASE,\n",
    "    IKEA_DATABASE_DTYPES,\n",
    ")\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from willitfit.app_utils.googlecloud import get_cloud_data, send_cloud_data\n",
    "\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import chromedriver_binary\n",
    "\n",
    "# Define path to database\n",
    "DATABASE_PATH = DATA_FOLDER + \"/\" + ARTICLE_DATABASE\n",
    "\n",
    "\n",
    "def chrome_settings():\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    return chrome_options\n",
    "\n",
    "\n",
    "def scrape_product(\n",
    "    article_code,\n",
    "    country_domain=IKEA_COUNTRY_DOMAIN,\n",
    "    website_language=IKEA_WEBSITE_LANGUAGE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Scrape the artikle from Ikea website\n",
    "    Filter out part of the site with important informations.\n",
    "    When we run the test first time,\n",
    "    latest version of chromedriver binary is downloaded and saved in cache\n",
    "    and it is reused every time we run tests.\n",
    "    If your browser auto updates the version,\n",
    "    then the respective chromedriver is auto downloaded\n",
    "    and updated when running tests.\n",
    "    \"\"\"\n",
    "    # Ikea url\n",
    "    IKEA_URL = f\"https://www.ikea.com/{country_domain}/{website_language}/\"\n",
    "    IKEA_SEARCH_URL = f\"search/products/?q=\"\n",
    "    # Request to check if website exsist, if not return str\n",
    "    r = requests.get(os.path.join(IKEA_URL, IKEA_SEARCH_URL, article_code))\n",
    "    if r.status_code == 404:\n",
    "        return WEBSITE_UNAVAILABLE\n",
    "    # Scrap website and select relevant part of the website\n",
    "    driver = webdriver.Chrome(\n",
    "        ChromeDriverManager().install(), options=chrome_settings()\n",
    "    )\n",
    "    driver.get(os.path.join(IKEA_URL, IKEA_SEARCH_URL, article_code))\n",
    "    try:\n",
    "        important_part_of_page = driver.find_element_by_class_name(\"results__list\")\n",
    "        # Check if the article exists, if not return str\n",
    "        tag = important_part_of_page.find_element_by_tag_name(\"a\")\n",
    "    except:\n",
    "        return ARTICLE_NOT_FOUND\n",
    "    # if article exists return important part of page\n",
    "    # https://stackoverflow.com/questions/48665001/can-not-click-on-a-element-elementclickinterceptedexception-in-splinter-selen\n",
    "    driver.execute_script(\"arguments[0].click();\", tag)\n",
    "    \n",
    "    time.sleep(30)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    important_part_of_page = soup.find_all(\n",
    "        \"div\", {\"id\": \"SEC_product-details-packaging\"}\n",
    "    )\n",
    "\n",
    "    return important_part_of_page[0]\n",
    "\n",
    "def inch_to_cm(d):\n",
    "    for k,v in d.items():\n",
    "        if k in ['width','height','length']:\n",
    "            v*2.54\n",
    "            d[k] = v*2.54\n",
    "    return d\n",
    "\n",
    "def extract_numeric_product_to_dict(product_features):\n",
    "    \"\"\"\n",
    "    Extract features from string and save it in dict\n",
    "    with following keys ['width','high','length','weight','packages']\n",
    "    \"\"\"\n",
    "    info_dict = {}\n",
    "    new_columns_name = [\"width\", \"height\", \"length\", \"weight\", \"packages\"]\n",
    "\n",
    "    for info in product_features:\n",
    "        info_item = info.split()\n",
    "        print(info)\n",
    "        for i, x in enumerate(info_item):\n",
    "            print(x)\n",
    "            \n",
    "            try:\n",
    "                float(x)\n",
    "                info_dict[info_item[0]] = float(info_item[1])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "            \n",
    "    # prepare dict for product with only 2 dimensions\n",
    "    if any(['cm' in x for x in product_features]):\n",
    "        info_not_all_dimensions_given = {}\n",
    "        if len(info_dict) == 4:\n",
    "            info_not_all_dimensions_given[new_columns_name[0]] = list(info_dict.values())[0]\n",
    "            info_not_all_dimensions_given[new_columns_name[1]] = list(info_dict.values())[2]\n",
    "            info_not_all_dimensions_given[new_columns_name[2]] = list(info_dict.values())[2]\n",
    "            info_not_all_dimensions_given[new_columns_name[3]] = list(info_dict.values())[1]\n",
    "            info_not_all_dimensions_given[new_columns_name[4]] = list(info_dict.values())[3]\n",
    "            return info_not_all_dimensions_given\n",
    "        info_dict = {x: y for x, y in zip(new_columns_name, info_dict.values())}\n",
    "        return info_dict\n",
    "    else:\n",
    "        info_not_all_dimensions_given = {}\n",
    "        if len(info_dict) == 4:\n",
    "            info_not_all_dimensions_given[new_columns_name[0]] = list(info_dict.values())[0]\n",
    "            info_not_all_dimensions_given[new_columns_name[1]] = list(info_dict.values())[2]\n",
    "            info_not_all_dimensions_given[new_columns_name[2]] = list(info_dict.values())[2]\n",
    "            info_not_all_dimensions_given[new_columns_name[3]] = list(info_dict.values())[1]\n",
    "            info_not_all_dimensions_given[new_columns_name[4]] = list(info_dict.values())[3]\n",
    "            return inch_to_cm(info_not_all_dimensions_given)\n",
    "        info_dict = {x: y for x, y in zip(new_columns_name, info_dict.values())}\n",
    "        return inch_to_cm(info_dict)\n",
    "\n",
    "\n",
    "def packages_dimensions_weights(page):\n",
    "    \"\"\"\n",
    "    Create data frame with information about subarticles\n",
    "    \"\"\"\n",
    "    # filter out important info with beautiful soup\n",
    "    info = page.find_all(\"div\", {\"class\": \"range-revamp-product-details__container\"})\n",
    "    number = page.find_all(\"span\", {\"class\": \"range-revamp-product-identifier__value\"})\n",
    "    product_name = page.find_all(\n",
    "        \"span\", {\"class\": \"range-revamp-product-details__header notranslate\"}\n",
    "    )[0].text\n",
    "    # create empty list\n",
    "    list_of_products = []\n",
    "    # create empty dict\n",
    "    product_info = {}\n",
    "    \n",
    "    # extract subarticle code and parameters for all subproducts in product\n",
    "    for i, (x, y) in enumerate(zip(number, info)):\n",
    "  \n",
    "        print(x.text)\n",
    "\n",
    "        \n",
    "        y_info = [\n",
    "            info.text\n",
    "            for info in y.find_all(\n",
    "                \"span\", {\"class\": \"range-revamp-product-details__label\"}\n",
    "                \n",
    "            )\n",
    "            \n",
    "        ]\n",
    "        print('xxxxx')\n",
    "        \n",
    "        print(extract_numeric_product_to_dict(y_info))\n",
    "\n",
    "        \n",
    "              \n",
    "        \n",
    "        # append to dict\n",
    "        \n",
    "        product_info = extract_numeric_product_to_dict(y_info)\n",
    "        product_info[\"subarticle_code\"] = x.text.replace(\".\", \"\")\n",
    "        product_info[\"product_name\"] = product_name\n",
    "        # append to list\n",
    "        list_of_products.append(product_info)\n",
    "\n",
    "    return pd.DataFrame(list_of_products)\n",
    "\n",
    "\n",
    "def df_to_list(df, article_code):\n",
    "    \"\"\"\n",
    "    Prepare output for API from data frame.\n",
    "    [(\n",
    "    article_code (str),\n",
    "    item_count (int),\n",
    "        [(\n",
    "        package_id (int),\n",
    "        package_length (int),\n",
    "        package_width (int),\n",
    "        package_height (int),\n",
    "        package_weight (float)\n",
    "        )]\n",
    "    )]\n",
    "    \"\"\"\n",
    "    # Initialize empty list\n",
    "    return_list = []\n",
    "\n",
    "    # Loop over each article\n",
    "    for article, article_count in article_code.items():\n",
    "        # Sub-list when there are multiple packages\n",
    "        package_list = []\n",
    "        # Find all matches in dataframe\n",
    "        matched_packages = df[df[\"article_code\"] == article]\n",
    "        # Loop over all packages\n",
    "        package_count = 1\n",
    "        for _, matched_package in matched_packages.iterrows():\n",
    "            # If the same package exists multiple times this will run more than once\n",
    "            for idx in range(int(matched_package[\"packages\"])):\n",
    "                package_list.append(\n",
    "                    (\n",
    "                        package_count,\n",
    "                        int(matched_package[\"height\"]),\n",
    "                        int(matched_package[\"width\"]),\n",
    "                        int(matched_package[\"length\"]),\n",
    "                        matched_package[\"weight\"],\n",
    "                    )\n",
    "                )\n",
    "                # Append package ID, dimensions and weight\n",
    "                package_count += 1\n",
    "        # Append list of packages\n",
    "        return_list.append([article, article_count, package_list])\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def product_info_and_update_csv_database(\n",
    "    article_dict, path_to_csv=DATABASE_PATH, item_count=1\n",
    "):\n",
    "    \"\"\"\n",
    "    Check if article exists in database, if not scrap it and update\n",
    "    Returns:\n",
    "        return_list - list required for optimizer\n",
    "        product_names - pd.dataframe containing article_code & product_name\n",
    "    \"\"\"\n",
    "    # Only use article keys here\n",
    "    article_code = [*article_dict]\n",
    "\n",
    "    ikea_database = get_cloud_data(path_to_csv)\n",
    "    # Reduce size\n",
    "    ikea_database = ikea_database.astype(IKEA_DATABASE_DTYPES)\n",
    "    all_ordered_product_df = pd.DataFrame()\n",
    "    new_product_for_database = pd.DataFrame()\n",
    "    return_list = []\n",
    "\n",
    "    for i, x in enumerate(article_code):\n",
    "        print(article_code)\n",
    "        \n",
    "        # If article exists in database already\n",
    "        if ikea_database.shape[0] > 0 and (ikea_database[\"article_code\"] == x).any():\n",
    "            all_ordered_product_df = all_ordered_product_df.append(\n",
    "                ikea_database[ikea_database[\"article_code\"] == x]\n",
    "            )\n",
    "        # If not\n",
    "        else:\n",
    "            page = scrape_product(\n",
    "                x,\n",
    "                country_domain=IKEA_COUNTRY_DOMAIN,\n",
    "                website_language=IKEA_WEBSITE_LANGUAGE,\n",
    "            )\n",
    "            if page == WEBSITE_UNAVAILABLE:\n",
    "                return WEBSITE_UNAVAILABLE\n",
    "            if page == ARTICLE_NOT_FOUND:\n",
    "                return ARTICLE_NOT_FOUND\n",
    "            df = packages_dimensions_weights(page)\n",
    "            df[\"article_code\"] = x\n",
    "            all_ordered_product_df = all_ordered_product_df.append(df).astype(\n",
    "                IKEA_DATABASE_DTYPES\n",
    "            )\n",
    "            new_product_for_database = new_product_for_database.append(df)\n",
    "\n",
    "    product_names = all_ordered_product_df[[\"article_code\", \"product_name\"]].drop_duplicates().set_index(\n",
    "        [\"article_code\"]\n",
    "    )\n",
    "\n",
    "    return_list = df_to_list(all_ordered_product_df, article_dict)\n",
    "    # Append new items and reduce size\n",
    "    \n",
    "    \n",
    "    ikea_database = ikea_database.append(new_product_for_database).astype(\n",
    "        IKEA_DATABASE_DTYPES\n",
    "    )\n",
    "    # Write to csv\n",
    "    write_file = send_cloud_data(ikea_database, path_to_csv)\n",
    "    if write_file != True:\n",
    "        # TODO\n",
    "        return \"Error writing to file\"\n",
    "    return return_list, product_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8676fede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['29303775 ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 88.0.4324\n",
      "Get LATEST driver version for 88.0.4324\n",
      "Driver [/home/kasia/.wdm/drivers/chromedriver/linux64/88.0.4324.96/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502.051.79\n",
      "xxxxx\n",
      "Artikelnummer:\n",
      "Artikelnummer:\n",
      "Breite: 66 cm\n",
      "Breite:\n",
      "66\n",
      "cm\n",
      "Höhe: 15 cm\n",
      "Höhe:\n",
      "15\n",
      "cm\n",
      "Länge: 84 cm\n",
      "Länge:\n",
      "84\n",
      "cm\n",
      "Gewicht: 15.00 kg\n",
      "Gewicht:\n",
      "15.00\n",
      "kg\n",
      "Paket(e): 2\n",
      "Paket(e):\n",
      "2\n",
      "{'width': 66.0, 'height': 15.0, 'length': 84.0, 'weight': 15.0, 'packages': 2.0}\n",
      "Artikelnummer:\n",
      "Artikelnummer:\n",
      "Breite: 66 cm\n",
      "Breite:\n",
      "66\n",
      "cm\n",
      "Höhe: 15 cm\n",
      "Höhe:\n",
      "15\n",
      "cm\n",
      "Länge: 84 cm\n",
      "Länge:\n",
      "84\n",
      "cm\n",
      "Gewicht: 15.00 kg\n",
      "Gewicht:\n",
      "15.00\n",
      "kg\n",
      "Paket(e): 2\n",
      "Paket(e):\n",
      "2\n",
      "602.051.88\n",
      "xxxxx\n",
      "Breite: 66 cm\n",
      "Breite:\n",
      "66\n",
      "cm\n",
      "Höhe: 15 cm\n",
      "Höhe:\n",
      "15\n",
      "cm\n",
      "Länge: 84 cm\n",
      "Länge:\n",
      "84\n",
      "cm\n",
      "Gewicht: 15.00 kg\n",
      "Gewicht:\n",
      "15.00\n",
      "kg\n",
      "Paket(e): 2\n",
      "Paket(e):\n",
      "2\n",
      "{'width': 66.0, 'height': 15.0, 'length': 84.0, 'weight': 15.0, 'packages': 2.0}\n",
      "Breite: 66 cm\n",
      "Breite:\n",
      "66\n",
      "cm\n",
      "Höhe: 15 cm\n",
      "Höhe:\n",
      "15\n",
      "cm\n",
      "Länge: 84 cm\n",
      "Länge:\n",
      "84\n",
      "cm\n",
      "Gewicht: 15.00 kg\n",
      "Gewicht:\n",
      "15.00\n",
      "kg\n",
      "Paket(e): 2\n",
      "Paket(e):\n",
      "2\n",
      "802.134.46\n",
      "xxxxx\n",
      "Artikelnummer:\n",
      "Artikelnummer:\n",
      "Breite: 66 cm\n",
      "Breite:\n",
      "66\n",
      "cm\n",
      "Höhe: 13 cm\n",
      "Höhe:\n",
      "13\n",
      "cm\n",
      "Länge: 84 cm\n",
      "Länge:\n",
      "84\n",
      "cm\n",
      "Gewicht: 12.00 kg\n",
      "Gewicht:\n",
      "12.00\n",
      "kg\n",
      "Paket(e): 1\n",
      "Paket(e):\n",
      "1\n",
      "{'width': 66.0, 'height': 13.0, 'length': 84.0, 'weight': 12.0, 'packages': 1.0}\n",
      "Artikelnummer:\n",
      "Artikelnummer:\n",
      "Breite: 66 cm\n",
      "Breite:\n",
      "66\n",
      "cm\n",
      "Höhe: 13 cm\n",
      "Höhe:\n",
      "13\n",
      "cm\n",
      "Länge: 84 cm\n",
      "Länge:\n",
      "84\n",
      "cm\n",
      "Gewicht: 12.00 kg\n",
      "Gewicht:\n",
      "12.00\n",
      "kg\n",
      "Paket(e): 1\n",
      "Paket(e):\n",
      "1\n",
      "304.110.62\n",
      "xxxxx\n",
      "Breite: 66 cm\n",
      "Breite:\n",
      "66\n",
      "cm\n",
      "Höhe: 13 cm\n",
      "Höhe:\n",
      "13\n",
      "cm\n",
      "Länge: 84 cm\n",
      "Länge:\n",
      "84\n",
      "cm\n",
      "Gewicht: 12.00 kg\n",
      "Gewicht:\n",
      "12.00\n",
      "kg\n",
      "Paket(e): 1\n",
      "Paket(e):\n",
      "1\n",
      "{'width': 66.0, 'height': 13.0, 'length': 84.0, 'weight': 12.0, 'packages': 1.0}\n",
      "Breite: 66 cm\n",
      "Breite:\n",
      "66\n",
      "cm\n",
      "Höhe: 13 cm\n",
      "Höhe:\n",
      "13\n",
      "cm\n",
      "Länge: 84 cm\n",
      "Länge:\n",
      "84\n",
      "cm\n",
      "Gewicht: 12.00 kg\n",
      "Gewicht:\n",
      "12.00\n",
      "kg\n",
      "Paket(e): 1\n",
      "Paket(e):\n",
      "1\n",
      "304.111.23\n",
      "xxxxx\n",
      "Artikelnummer:\n",
      "Artikelnummer:\n",
      "Breite: 65 cm\n",
      "Breite:\n",
      "65\n",
      "cm\n",
      "Höhe: 9 cm\n",
      "Höhe:\n",
      "9\n",
      "cm\n",
      "Länge: 66 cm\n",
      "Länge:\n",
      "66\n",
      "cm\n",
      "Gewicht: 8.20 kg\n",
      "Gewicht:\n",
      "8.20\n",
      "kg\n",
      "Paket(e): 1\n",
      "Paket(e):\n",
      "1\n",
      "{'width': 65.0, 'height': 9.0, 'length': 66.0, 'weight': 8.2, 'packages': 1.0}\n",
      "Artikelnummer:\n",
      "Artikelnummer:\n",
      "Breite: 65 cm\n",
      "Breite:\n",
      "65\n",
      "cm\n",
      "Höhe: 9 cm\n",
      "Höhe:\n",
      "9\n",
      "cm\n",
      "Länge: 66 cm\n",
      "Länge:\n",
      "66\n",
      "cm\n",
      "Gewicht: 8.20 kg\n",
      "Gewicht:\n",
      "8.20\n",
      "kg\n",
      "Paket(e): 1\n",
      "Paket(e):\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['29303775 ',\n",
       "   1,\n",
       "   [(1, 15, 66, 84, 15.0),\n",
       "    (2, 15, 66, 84, 15.0),\n",
       "    (3, 15, 66, 84, 15.0),\n",
       "    (4, 15, 66, 84, 15.0),\n",
       "    (5, 13, 66, 84, 12.0),\n",
       "    (6, 13, 66, 84, 12.0),\n",
       "    (7, 9, 65, 66, 8.2)]]],\n",
       "              product_name\n",
       " article_code             \n",
       " 29303775          ÄPPLARÖ)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_code = {'29303775 ':1}\n",
    "\n",
    "\n",
    "product_info_and_update_csv_database(article_code)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
